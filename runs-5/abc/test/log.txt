[10/16 23:29:26] main-logger INFO: arch: boundary_transformer
aug: True
bandwidth: 0.8
base_lr: 0.001
batch_size: 24
batch_size_test: 4
batch_size_val: 12
channels: [48, 96, 192, 384]
classes: 10
concat_xyz: True
data_name: abc
data_root: /file/fz20/st_dataset/ABC
depths: [2, 2, 6, 2]
dist_backend: nccl
dist_url: tcp://127.0.0.1:56945
distributed: True
downsample_scale: 8
drop_path_rate: 0.3
drop_rate: 0.5
epochs: 100
eval_freq: 1
evaluate: True
fea_dim: 6
grid_size: 0.01
grid_sizes: [0.01, 0.02, 0.04, 0.08]
ignore_label: -100
jitter_clip: 0.02
jitter_sigma: 0.005
k: 16
loop: 4
manual_seed: 123
max_batch_points: 400000
max_num_neighbors: 34
model_path: /home/fz20/Project/Prim-Stratified-Transformer/runs-5/abc/model/model_best.pth
momentum: 0.9
multiplier: 0.1
multiprocessing_distributed: True
names_path: data/s3dis/s3dis_names.txt
ngpus_per_node: 3
num_heads: [3, 6, 12, 24]
num_layers: 4
optimizer: AdamW
patch_size: 0.01
print_freq: 1
quant_size: 0.01
quant_sizes: [0.01, 0.02, 0.04, 0.08]
rank: 0
ratio: 0.25
rel_key: True
rel_query: True
rel_value: True
resume: None
save_folder: runs-5/abc/test
save_freq: 1
save_path: runs-5/abc/test
scheduler: MultiStep
scheduler_update: epoch
split: val
start_epoch: 0
stem_transformer: True
step_epoch: 30
sync_bn: True
test_area: 5
test_gpu: [0]
test_list: dataset/s3dis/list/val5.txt
test_list_full: dataset/s3dis/list/val5_full.txt
test_workers: 4
train_gpu: [2, 3, 4]
transformer_lr_scale: 0.1
up_k: 3
use_amp: True
use_xyz: True
visual: True
voxel_max: 80000
voxel_size: 0.005
warmup: linear
warmup_iters: 1500
warmup_ratio: 1e-06
weight: None
weight_decay: 0.01
window_size: [0.01, 0.02, 0.04, 0.08]
workers: 16
world_size: 3
[10/16 23:29:26] main-logger INFO: => creating model ...
[10/16 23:29:26] main-logger INFO: Classes: 10
[10/16 23:29:26] main-logger INFO: Stratified(
  (stem_layer): ModuleList(
    (0): KPConvSimpleBlock(
      (kpconv): KPConvLayer(InF: 6, OutF: 48, kernel_pts: 15, radius: 0.01, KP_influence: linear, Add_one: False)
      (bn): FastBatchNorm1d(
        (batch_norm): BatchNorm1d(48, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
      )
      (activation): LeakyReLU(negative_slope=0.2)
    )
  )
  (layers): ModuleList(
    (0): BasicLayer(
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=48, out_features=144, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=48, out_features=48, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=48, out_features=192, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=192, out_features=48, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=48, out_features=144, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=48, out_features=48, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.027)
          (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=48, out_features=192, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=192, out_features=48, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
      )
      (downsample): TransitionDown(
        (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
        (linear): Linear(in_features=48, out_features=96, bias=False)
        (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      )
    )
    (1): BasicLayer(
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.055)
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.082)
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
      )
      (downsample): TransitionDown(
        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        (linear): Linear(in_features=96, out_features=192, bias=False)
        (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      )
    )
    (2): BasicLayer(
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.109)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.136)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (2): SwinTransformerBlock(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.164)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (3): SwinTransformerBlock(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.191)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (4): SwinTransformerBlock(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.218)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (5): SwinTransformerBlock(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.245)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
      )
      (downsample): TransitionDown(
        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (linear): Linear(in_features=192, out_features=384, bias=False)
        (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      )
    )
    (3): BasicLayer(
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.273)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.300)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
      )
    )
  )
  (upsamples): ModuleList(
    (0): Upsample(
      (linear1): Sequential(
        (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=192, out_features=192, bias=True)
      )
      (linear2): Sequential(
        (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=384, out_features=192, bias=True)
      )
    )
    (1): Upsample(
      (linear1): Sequential(
        (0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=96, out_features=96, bias=True)
      )
      (linear2): Sequential(
        (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=192, out_features=96, bias=True)
      )
    )
    (2): Upsample(
      (linear1): Sequential(
        (0): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=48, out_features=48, bias=True)
      )
      (linear2): Sequential(
        (0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=96, out_features=48, bias=True)
      )
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=48, out_features=48, bias=True)
    (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=48, out_features=10, bias=True)
  )
  (embedding): Sequential(
    (0): Linear(in_features=48, out_features=48, bias=True)
    (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=48, out_features=48, bias=True)
  )
  (boundary): Sequential(
    (0): Linear(in_features=48, out_features=48, bias=True)
    (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=48, out_features=2, bias=True)
  )
)
[10/16 23:29:26] main-logger INFO: #Model parameters: 6837849
[10/16 23:29:26] main-logger INFO: use SyncBN
[10/16 23:29:32] main-logger INFO: => loading weight '/home/fz20/Project/Prim-Stratified-Transformer/runs-5/abc/model/model_best.pth'
[10/16 23:29:33] main-logger INFO: => loaded weight '/home/fz20/Project/Prim-Stratified-Transformer/runs-5/abc/model/model_best.pth'
[10/16 23:29:33] main-logger INFO: train_data samples: '17992'
[10/16 23:29:33] main-logger INFO: >>>>>>>>>>>>>>>> Start Evaluation >>>>>>>>>>>>>>>>
[10/16 23:35:30] main-logger INFO: arch: boundary_transformer
aug: True
bandwidth: 0.8
base_lr: 0.001
batch_size: 24
batch_size_test: 4
batch_size_val: 6
channels: [48, 96, 192, 384]
classes: 10
concat_xyz: True
data_name: abc
data_root: /file/fz20/st_dataset/ABC
depths: [2, 2, 6, 2]
dist_backend: nccl
dist_url: tcp://127.0.0.1:53115
distributed: True
downsample_scale: 8
drop_path_rate: 0.3
drop_rate: 0.5
epochs: 100
eval_freq: 1
evaluate: True
fea_dim: 6
grid_size: 0.01
grid_sizes: [0.01, 0.02, 0.04, 0.08]
ignore_label: -100
jitter_clip: 0.02
jitter_sigma: 0.005
k: 16
loop: 4
manual_seed: 123
max_batch_points: 400000
max_num_neighbors: 34
model_path: /home/fz20/Project/Prim-Stratified-Transformer/runs-5/abc/model/model_best.pth
momentum: 0.9
multiplier: 0.1
multiprocessing_distributed: True
names_path: data/s3dis/s3dis_names.txt
ngpus_per_node: 3
num_heads: [3, 6, 12, 24]
num_layers: 4
optimizer: AdamW
patch_size: 0.01
print_freq: 1
quant_size: 0.01
quant_sizes: [0.01, 0.02, 0.04, 0.08]
rank: 0
ratio: 0.25
rel_key: True
rel_query: True
rel_value: True
resume: None
save_folder: runs-5/abc/test
save_freq: 1
save_path: runs-5/abc/test
scheduler: MultiStep
scheduler_update: epoch
split: val
start_epoch: 0
stem_transformer: True
step_epoch: 30
sync_bn: True
test_area: 5
test_gpu: [0]
test_list: dataset/s3dis/list/val5.txt
test_list_full: dataset/s3dis/list/val5_full.txt
test_workers: 4
train_gpu: [2, 3, 4]
transformer_lr_scale: 0.1
up_k: 3
use_amp: True
use_xyz: True
visual: True
voxel_max: 80000
voxel_size: 0.005
warmup: linear
warmup_iters: 1500
warmup_ratio: 1e-06
weight: None
weight_decay: 0.01
window_size: [0.01, 0.02, 0.04, 0.08]
workers: 16
world_size: 3
[10/16 23:35:30] main-logger INFO: => creating model ...
[10/16 23:35:30] main-logger INFO: Classes: 10
[10/16 23:35:30] main-logger INFO: Stratified(
  (stem_layer): ModuleList(
    (0): KPConvSimpleBlock(
      (kpconv): KPConvLayer(InF: 6, OutF: 48, kernel_pts: 15, radius: 0.01, KP_influence: linear, Add_one: False)
      (bn): FastBatchNorm1d(
        (batch_norm): BatchNorm1d(48, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
      )
      (activation): LeakyReLU(negative_slope=0.2)
    )
  )
  (layers): ModuleList(
    (0): BasicLayer(
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=48, out_features=144, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=48, out_features=48, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=48, out_features=192, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=192, out_features=48, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=48, out_features=144, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=48, out_features=48, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.027)
          (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=48, out_features=192, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=192, out_features=48, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
      )
      (downsample): TransitionDown(
        (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
        (linear): Linear(in_features=48, out_features=96, bias=False)
        (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      )
    )
    (1): BasicLayer(
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.055)
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.082)
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
      )
      (downsample): TransitionDown(
        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        (linear): Linear(in_features=96, out_features=192, bias=False)
        (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      )
    )
    (2): BasicLayer(
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.109)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.136)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (2): SwinTransformerBlock(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.164)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (3): SwinTransformerBlock(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.191)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (4): SwinTransformerBlock(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.218)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (5): SwinTransformerBlock(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.245)
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
      )
      (downsample): TransitionDown(
        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (linear): Linear(in_features=192, out_features=384, bias=False)
        (pool): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)
      )
    )
    (3): BasicLayer(
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.273)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=True)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath(drop_prob=0.300)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=True)
          )
        )
      )
    )
  )
  (upsamples): ModuleList(
    (0): Upsample(
      (linear1): Sequential(
        (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=192, out_features=192, bias=True)
      )
      (linear2): Sequential(
        (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=384, out_features=192, bias=True)
      )
    )
    (1): Upsample(
      (linear1): Sequential(
        (0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=96, out_features=96, bias=True)
      )
      (linear2): Sequential(
        (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=192, out_features=96, bias=True)
      )
    )
    (2): Upsample(
      (linear1): Sequential(
        (0): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=48, out_features=48, bias=True)
      )
      (linear2): Sequential(
        (0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=96, out_features=48, bias=True)
      )
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=48, out_features=48, bias=True)
    (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=48, out_features=10, bias=True)
  )
  (embedding): Sequential(
    (0): Linear(in_features=48, out_features=48, bias=True)
    (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=48, out_features=48, bias=True)
  )
  (boundary): Sequential(
    (0): Linear(in_features=48, out_features=48, bias=True)
    (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=48, out_features=2, bias=True)
  )
)
[10/16 23:35:30] main-logger INFO: #Model parameters: 6837849
[10/16 23:35:30] main-logger INFO: use SyncBN
[10/16 23:35:35] main-logger INFO: => loading weight '/home/fz20/Project/Prim-Stratified-Transformer/runs-5/abc/model/model_best.pth'
[10/16 23:35:35] main-logger INFO: => loaded weight '/home/fz20/Project/Prim-Stratified-Transformer/runs-5/abc/model/model_best.pth'
[10/16 23:35:35] main-logger INFO: train_data samples: '17992'
[10/16 23:35:35] main-logger INFO: >>>>>>>>>>>>>>>> Start Evaluation >>>>>>>>>>>>>>>>
[10/16 23:40:48] main-logger INFO: Test: [1/12] Data 5.935 (5.935) Batch 313.374 (313.374) Feat_Loss 0.1443 (0.1443) Type_Loss 0.1048 (0.1048) Boundary_Loss 0.1011 (0.1011) Seg_IoU 0.4336 (0.4336) Type_IoU 0.7172 (0.7172).
[10/17 00:02:27] main-logger INFO: Test: [2/12] Data 0.005 (2.970) Batch 1298.208 (805.791) Feat_Loss 0.0848 (0.1145) Type_Loss 0.0578 (0.0813) Boundary_Loss 0.0408 (0.0709) Seg_IoU 0.8031 (0.6184) Type_IoU 1.0000 (0.8586).
[10/17 09:38:12] main-logger INFO: Test: [3/12] Data 4.788 (3.576) Batch 34545.538 (12052.373) Feat_Loss 0.0662 (0.0984) Type_Loss 0.2522 (0.1383) Boundary_Loss 0.0326 (0.0582) Seg_IoU 0.5856 (0.6075) Type_IoU 0.9405 (0.8859).
